{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Atlas API helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baseUrl = \"http://%s:21000/api/atlas\" % os.environ['ATLAS_SERVER']\n",
    "user = \"admin\"\n",
    "password = \"admin\"\n",
    "cluster = \"Demo\"\n",
    "\n",
    "def getAtlas(path):\n",
    "    r = requests.get(\"%s/%s\" % (baseUrl, path), \\\n",
    "                     auth=(user, password))\n",
    "    return r.json()\n",
    "\n",
    "def postAtlas(path, content):\n",
    "    r = requests.post(\"%s/%s\" % (baseUrl, path), \\\n",
    "                      json=content, \\\n",
    "                      auth=(user, password), \\\n",
    "                      headers={\"Content-Type\": \"application/json;charset=UTF-8\"}\n",
    "                     )\n",
    "    return r.json()\n",
    "\n",
    "def deleteAtlas(path):\n",
    "    print \"%s/%s\" % (baseUrl, path)\n",
    "    r = requests.delete(\"%s/%s\" % (baseUrl, path), \\\n",
    "                        auth=(user, password))\n",
    "    return r\n",
    "    \n",
    "def getHiveTable(qualifiedTable, cluster):\n",
    "    path = \"entities?type=hive_table&property=qualifiedName&value=%s@%s\" % (qualifiedTable, cluster)\n",
    "    return getAtlas(path)\n",
    "\n",
    "def getHiveDB(dbName, cluster):\n",
    "    path = \"entities?type=hive_db&property=qualifiedName&value=%s@%s\" % (dbName, cluster)\n",
    "    return getAtlas(path)\n",
    "    \n",
    "def createType(content):\n",
    "    return postAtlas(\"types\", content)\n",
    "\n",
    "def createEntity(content):\n",
    "    return postAtlas(\"entities\", content)\n",
    "\n",
    "def updateEntity(guid, content):\n",
    "    return postAtlas(\"entities/%s\" % guid, content)\n",
    "\n",
    "def deleteEntity(path):\n",
    "    return deleteAtlas(\"entities?guid=%s\" % path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Create Spark Process Type in Atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spark_etl_process = {\n",
    "    u'enumTypes': [],\n",
    "    u'structTypes': [],\n",
    "    u'traitTypes': [],\n",
    "    u'classTypes': [\n",
    "        {\n",
    "            u'hierarchicalMetaTypeName': u'org.apache.atlas.typesystem.types.ClassType',\n",
    "            u'typeName': u'spark_etl_process',\n",
    "            u'typeDescription': None,\n",
    "            u'superTypes': [u'Process'],\n",
    "            u'attributeDefinitions': [\n",
    "                {\n",
    "                    u'isUnique': False,\n",
    "                    u'name': u'etl_code',\n",
    "                    u'reverseAttributeName': None,\n",
    "                    u'multiplicity': u'required',\n",
    "                    u'dataTypeName': u'string',\n",
    "                    u'isIndexable': True,\n",
    "                    u'isComposite': False\n",
    "                },\n",
    "                {\n",
    "                    u'isUnique': False,\n",
    "                    u'name': u'packages',\n",
    "                    u'reverseAttributeName': None,\n",
    "                    u'multiplicity': u'optional',\n",
    "                    u'dataTypeName': u'array<string>',\n",
    "                    u'isIndexable': False,\n",
    "                    u'isComposite': False\n",
    "                },\n",
    "                {\n",
    "                    u'isUnique': False,\n",
    "                    u'name': u'startTime',\n",
    "                    u'reverseAttributeName': None,\n",
    "                    u'multiplicity': u'required',\n",
    "                    u'dataTypeName': u'date',\n",
    "                    u'isIndexable': False,\n",
    "                    u'isComposite': False\n",
    "                },\n",
    "                {\n",
    "                    u'isUnique': False,\n",
    "                    u'name': u'endTime',\n",
    "                    u'reverseAttributeName': None,\n",
    "                    u'multiplicity': u'required',\n",
    "                    u'dataTypeName': u'date',\n",
    "                    u'isIndexable': False,\n",
    "                    u'isComposite': False\n",
    "                },\n",
    "                {\n",
    "                    u'isUnique': False,\n",
    "                    u'name': u'userName',\n",
    "                    u'reverseAttributeName': None,\n",
    "                    u'multiplicity': u'optional',\n",
    "                    u'dataTypeName': u'string',\n",
    "                    u'isIndexable': True,\n",
    "                    u'isComposite': False\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "createType(spark_etl_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Define the ETL job configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clusterName = \"Demo\"\n",
    "\n",
    "sourceDB = \"employees\"\n",
    "sourceTables = (\"employees.employees\", \"employees.departments\", \"employees.dept_emp\")\n",
    "targetTableName = \"emp_dept_flat3\"\n",
    "targetDB = \"default\"\n",
    "targetTable = \"%s.%s\" % (targetDB, targetTableName)\n",
    "targetColumns = [\"dept_no:string\", \"emp_no:int\", \"full_name:string\", \n",
    "                \"from_date:string\", \"to_date:string\", \"dept_name:string\"]\n",
    "\n",
    "transformation = \"\"\"<pre>\n",
    "val employees = sqlContext.sql(\"select * from employees.employees\")\n",
    "val departments = sqlContext.sql(\"select * from employees.departments\")\n",
    "val dept_emp = sqlContext.sql(\"select * from employees.dept_emp\")\n",
    "\n",
    "val flat = employees.withColumn(\"full_name\", concat(employees(\"last_name\"), lit(\", \"), employees(\"first_name\")))\n",
    ".select(\"full_name\", \"emp_no\")\n",
    ".join(dept_emp,\"emp_no\")\n",
    ".join(departments, \"dept_no\")\n",
    "</pre>\"\"\"\n",
    "\n",
    "owner = \"etl\"\n",
    "\n",
    "createTime = \"2016-11-25T14:25:48.000Z\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Get GUIDS of involved databses and tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dbs': {'default': u'5c15c3f5-b465-458a-8b52-b188960853d7',\n",
       "  'employees': u'a9f9d3b8-a42d-4638-a308-16e4fbeb9c29'},\n",
       " 'tables': {'employees.departments': u'f08b9a13-10f5-494c-8173-87b928a9788b',\n",
       "  'employees.dept_emp': u'cd0f7a13-13c6-4fc7-8fc6-e3e473ad61a7',\n",
       "  'employees.employees': u'5110e28a-7954-414b-b375-2c877cf4be80'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guids = {\"dbs\": {}, \"tables\": {}}\n",
    "\n",
    "for table in sourceTables:\n",
    "    tableDef = getHiveTable(\"%s\" % table, clusterName)\n",
    "    guids[\"tables\"][table] = tableDef[\"definition\"][\"id\"][\"id\"]\n",
    "\n",
    "for database in [sourceDB, targetDB]:\n",
    "    guids[\"dbs\"][\"%s\" % database] = getHiveDB(database, clusterName)[\"definition\"][\"id\"][\"id\"]\n",
    "\n",
    "guids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Create Atlas Entity for new Hive table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Some Helpers for creating hive entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createHiveColumnJson(tableGUID, columnGuid, \n",
    "                         databaseName, tableName, clusterName, columnName, columnType, owner):\n",
    "    \n",
    "    hiveColumnDef = {\n",
    "        \"jsonClass\": \"org.apache.atlas.typesystem.json.InstanceSerialization$_Reference\",\n",
    "        \"id\": {\n",
    "          \"jsonClass\": \"org.apache.atlas.typesystem.json.InstanceSerialization$_Id\",\n",
    "          \"id\": (\"%20d\" % columnGuid).strip(),\n",
    "          \"version\": 0,\n",
    "          \"typeName\": \"hive_column\",\n",
    "          \"state\": \"ACTIVE\"\n",
    "        },\n",
    "        \"typeName\": \"hive_column\",\n",
    "        \"values\": {\n",
    "          \"name\": \"%s\" % columnName,\n",
    "          \"description\": None,\n",
    "          \"qualifiedName\": \"%s.%s.%s@%s\" % (databaseName, tableName, columnName, clusterName),\n",
    "          \"comment\": None,\n",
    "          \"owner\": \"%s\" % owner,\n",
    "          \"type\": \"%s\" % columnType,\n",
    "          \"table\": {\n",
    "            \"jsonClass\": \"org.apache.atlas.typesystem.json.InstanceSerialization$_Id\",\n",
    "            \"id\": \"%s\" % tableGUID,\n",
    "            \"version\": 0,\n",
    "            \"typeName\": \"hive_table\",\n",
    "            \"state\": \"ACTIVE\"\n",
    "          }\n",
    "        },\n",
    "        \"traitNames\": [ ],\n",
    "        \"traits\": {  }\n",
    "    }\n",
    "    \n",
    "    return hiveColumnDef\n",
    "\n",
    "    \n",
    "def createHiveTableJson(databaseGuid, tableGuid,\n",
    "                        databaseName, tableName, clusterName, createTime, owner):\n",
    "    hiveTableDef = {\n",
    "      \"jsonClass\": \"org.apache.atlas.typesystem.json.InstanceSerialization$_Reference\",\n",
    "      \"id\": {\n",
    "        \"jsonClass\": \"org.apache.atlas.typesystem.json.InstanceSerialization$_Id\",\n",
    "        \"id\": (\"%20d\" % tableGuid).strip(),\n",
    "        \"version\": 0,\n",
    "        \"typeName\": \"hive_table\",\n",
    "        \"state\": \"ACTIVE\"\n",
    "      },\n",
    "      \"typeName\": \"hive_table\",\n",
    "      \"values\": {\n",
    "        \"aliases\": None,\n",
    "        \"tableType\": \"MANAGED_TABLE\",\n",
    "        \"name\": \"%s\" % tableName,\n",
    "        \"viewExpandedText\": None,\n",
    "        \"createTime\": \"%s\" % createTime,\n",
    "        \"description\": None,\n",
    "        \"temporary\": False,\n",
    "        \"db\": {\n",
    "          \"jsonClass\": \"org.apache.atlas.typesystem.json.InstanceSerialization$_Id\",\n",
    "          \"id\": \"%s\" % databaseGuid,\n",
    "          \"version\": 0,\n",
    "          \"typeName\": \"hive_db\",\n",
    "          \"state\": \"ACTIVE\"\n",
    "        },\n",
    "        \"viewOriginalText\": None,\n",
    "        \"retention\": 0,\n",
    "        \"qualifiedName\": \"%s.%s@%s\" % (databaseName, tableName, clusterName),\n",
    "        \"columns\": [ ],\n",
    "        \"comment\": None,\n",
    "        \"lastAccessTime\": \"2016-11-02T14:25:48.000Z\",\n",
    "        \"owner\": \"%s\" % owner,\n",
    "        \"partitionKeys\": None\n",
    "      },\n",
    "      \"traitNames\": [ ],\n",
    "      \"traits\": { }\n",
    "    }\n",
    "\n",
    "    return hiveTableDef\n",
    "\n",
    "def createUpdateHiveTableJson(tableGuid,\n",
    "                        databaseName, tableName, clusterName, createTime, owner):\n",
    "    hiveTableDef = {\n",
    "      \"jsonClass\": \"org.apache.atlas.typesystem.json.InstanceSerialization$_Reference\",\n",
    "      \"id\": {\n",
    "        \"jsonClass\": \"org.apache.atlas.typesystem.json.InstanceSerialization$_Id\",\n",
    "        \"id\": \"%s\" % tableGuid,\n",
    "        \"version\": 0,\n",
    "        \"typeName\": \"hive_table\",\n",
    "        \"state\": \"ACTIVE\"\n",
    "      },\n",
    "      \"typeName\": \"hive_table\",\n",
    "      \"values\": {\n",
    "        \"columns\": [ ],\n",
    "      },\n",
    "      \"traitNames\": [ ],\n",
    "      \"traits\": { }\n",
    "    }\n",
    "\n",
    "    return hiveTableDef\n",
    "\n",
    "def createColumnIdJson(columnGuid):\n",
    "    columnIdDef = { \"id\": {\n",
    "      \"jsonClass\": \"org.apache.atlas.typesystem.json.InstanceSerialization$_Id\",\n",
    "      \"id\": \"%s\" % columnGuid,\n",
    "      \"version\": 0,\n",
    "      \"typeName\": \"hive_column\",\n",
    "      \"state\": \"ACTIVE\"\n",
    "    }}\n",
    "    return columnIdDef\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Create Hive table without columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'1e6e1a06-c6ec-40e0-821a-ea31177b9bf6'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newTableGuid = -(time.time()*1000)\n",
    "\n",
    "hiveTable = createHiveTableJson(guids[\"dbs\"][targetDB], newTableGuid,\n",
    "                                targetDB, targetTableName, clusterName, createTime, owner)\n",
    "newTable = createEntity(hiveTable)\n",
    "\n",
    "newTableGuid = newTable[\"entities\"][\"created\"][0]\n",
    "newTableGuid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Create Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'ef9a4538-342e-4a51-9453-7cd142a95a53',\n",
       " u'0257f483-3412-44c3-b72c-419956b059a3',\n",
       " u'6dd4ae48-5d36-47e0-a974-38de5247e3fd',\n",
       " u'e51ea9d7-514d-4f80-b5e7-6ecf544c9313',\n",
       " u'76a4a59d-db29-4cd3-8191-edeae449c34c',\n",
       " u'e3dc83e4-4742-413a-9bd0-ee4576dd1cf4']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newColumnGuid = -(time.time()*1000)\n",
    "entities = []\n",
    "\n",
    "for columns in targetColumns:\n",
    "    newColumnGuid = newColumnGuid - 100\n",
    "    columnName, columnType = columns.split(\":\")\n",
    "    hiveColumn = createHiveColumnJson(newTableGuid, newColumnGuid,\n",
    "                                      \"default\", targetTableName, clusterName, columnName, columnType, \"etl\")\n",
    "    entities.append(hiveColumn)\n",
    "\n",
    "\n",
    "newColumns = createEntity(entities)\n",
    "newColumns[\"entities\"][\"created\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Add Columns to table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This can be executed multiple times (idempotent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'1e6e1a06-c6ec-40e0-821a-ea31177b9bf6']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updateHiveTable = createUpdateHiveTableJson(newTableGuid,\n",
    "                                           targetDB, targetTableName, clusterName, createTime, owner)\n",
    "\n",
    "columnIds = [createColumnIdJson(guid)[\"id\"] for guid in newColumns[\"entities\"][\"created\"]]\n",
    "updateHiveTable[\"values\"][\"columns\"] = columnIds\n",
    "\n",
    "updateEntity(newTableGuid, updateHiveTable)[\"entities\"][\"updated\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Create Lineage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createLineageJson(inputTableNames, inputTableGuids, \n",
    "                      outputTableName, outputTableGuid, \n",
    "                      clusterName, sparkCode, packages, startTime, endTime, owner):\n",
    "    newLineageGuid = -(time.time()*1000)\n",
    "    lineageDef = {\n",
    "        \"id\": {\n",
    "            \"id\": (\"%20d\" % newLineageGuid).strip(),\n",
    "            \"jsonClass\": \"org.apache.atlas.typesystem.json.InstanceSerialization$_Id\",\n",
    "            \"state\": \"ACTIVE\",\n",
    "            \"typeName\": \"spark_etl_process\",\n",
    "            \"version\": 0\n",
    "        },\n",
    "        \"typeName\": \"spark_etl_process\",\n",
    "        \"jsonClass\": \"org.apache.atlas.typesystem.json.InstanceSerialization$_Reference\",\n",
    "        \"values\": {\n",
    "            \"name\": \"Spark:%s->%s\" %(\",\".join(inputTableNames), outputTableName),\n",
    "            \"qualifiedName\": \"Spark(%s):%s->%s@%s\" %(startTime, \",\".join(inputTableNames), outputTableName, clusterName),\n",
    "            \"inputs\": [],\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"id\": \"%s\" % outputTableGuid,\n",
    "                    \"jsonClass\": \"org.apache.atlas.typesystem.json.InstanceSerialization$_Id\",\n",
    "                    \"state\": \"ACTIVE\",\n",
    "                    \"typeName\": \"hive_table\",\n",
    "                    \"version\": 0\n",
    "                }\n",
    "            ],\n",
    "            \"etl_code\": \"%s\"  % sparkCode,\n",
    "            \"packages\": \"%s\"  % packages,\n",
    "            \"startTime\": \"%s\" % startTime,\n",
    "            \"endTime\": \"%s\"   % endTime,\n",
    "            \"userName\": \"%s\"  % owner\n",
    "        },\n",
    "        \"traitNames\": [],\n",
    "        \"traits\": {}\n",
    "    }\n",
    "    \n",
    "    for guid in inputTableGuids:\n",
    "        tableDef = {\n",
    "            \"id\": \"%s\" % guid,\n",
    "            \"jsonClass\": \"org.apache.atlas.typesystem.json.InstanceSerialization$_Id\",\n",
    "            \"state\": \"ACTIVE\",\n",
    "            \"typeName\": \"hive_table\",\n",
    "            \"version\": 0\n",
    "        }\n",
    "        lineageDef[\"values\"][\"inputs\"].append(tableDef)\n",
    "    \n",
    "    return lineageDef\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'6ec8e62e-a778-472c-aad6-33f3d254ce04']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineageDef = createLineageJson(sourceTables, [guids[\"tables\"][tableName] for tableName in sourceTables], \\\n",
    "                               targetTableName, newTableGuid, \\\n",
    "                               clusterName, transformation, [], \n",
    "                               \"2016-11-25T14:25:41.000Z\", \"2016-11-25T14:25:48.000Z\", owner)\n",
    "\n",
    "newLIneage = createEntity(lineageDef)\n",
    "newLIneage[\"entities\"][\"created\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Delete everything again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newGuids = newColumns[\"entities\"][\"created\"] + [newTableGuid] + newLIneage[\"entities\"][\"created\"]\n",
    "for g in newGuids:\n",
    "    print deleteEntity(g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
